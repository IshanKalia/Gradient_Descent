# Gradient_Descent
This project performs linear regression with a MSE loss function. After perfomring some explanatory data analytics, I standardise the variables. 
Furthermore, I construct a gradient descent algorithm from scratch to trace out how the loss value reduces as the number of iterations increasees. 
Secondly, I perform linear regression through stochastic gradient descent. In this method, samples of 7000 observations are selected at random from replacement with a value of theta (weight parameters) calculated for each sample. 
I have plotted the loss values for each iteration below each gradient descent algorithm. 
Further work will include hyperparameter tuning on the learning parameter, as well as trialling out different loss functions, such as the mean absolute deviation. 

